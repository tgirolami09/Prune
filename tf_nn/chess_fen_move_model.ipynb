{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d949afce",
   "metadata": {},
   "source": [
    "# Chess FEN → Score + Move Model\n",
    "This notebook:\n",
    "\n",
    "- Loads a `text` file where each line is `FEN|score_cp|other_cp|uci_move`.\n",
    "\n",
    "- Splits it into four pandas columns (should drop the last one because useless).\n",
    "\n",
    "- Encodes the FEN to numeric features (piece planes + side-to-move).\n",
    "\n",
    "- Trains:\n",
    "\n",
    "  A nn to predict the first centipawn score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a64ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 11:10:13.802347: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "# Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3c9667",
   "metadata": {},
   "source": [
    "## 1) Load & split raw lines into columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb9bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"../nnue/useful_chess_data.txt\"\n",
    "assert os.path.exists(DATA_PATH), f\"Data file not found at {DATA_PATH}. Upload your file there or change DATA_PATH.\"\n",
    "\n",
    "\n",
    "maxLines = int(10**7)\n",
    "amount = 38548203\n",
    "modulos_for_selection = (amount//maxLines)\n",
    "idx = 0\n",
    "lines = []\n",
    "skipped = 0\n",
    "with open(DATA_PATH, \"r\") as f:\n",
    "    for line in tqdm(f,desc=\"Reading positions\",total=amount):\n",
    "        line = line.strip()\n",
    "        if line and idx%modulos_for_selection==0:\n",
    "            lines.append(line)\n",
    "            if (len(lines)>=maxLines):\n",
    "                print(f\"Only using {len(lines)} lines\")\n",
    "                break\n",
    "        idx+=1\n",
    "\n",
    "df = pd.DataFrame([ln.split(\"|\") for ln in tqdm(lines,desc = \"Parsing chess data\")], columns=[\"fen\", \"score_cp\", \"score2_cp\", \"uci\"])\n",
    "df[\"score_cp\"] = pd.to_numeric(df[\"score_cp\"], errors=\"coerce\")\n",
    "df[\"score2_cp\"] = pd.to_numeric(df[\"score2_cp\"], errors=\"coerce\")\n",
    "df = df.drop(columns=[\"uci\"])\n",
    "df.to_pickle(path=\"fullDf.pkl\",compression=\"zip\")\n",
    "\n",
    "print(\"Parsed chess data (preview)\")\n",
    "print(df.head())\n",
    "\n",
    "del lines\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756191f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading normal df\n",
      "Dataframe has 10000000 entries\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading normal df\")\n",
    "df = pd.read_pickle(\"fullDf.pkl\",\"zip\")\n",
    "    \n",
    "print(f\"Dataframe has {len(df)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272aee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000\n",
      "2000000\n"
     ]
    }
   ],
   "source": [
    "#Reduce the size of loaded because it cannot fit into memory when training\n",
    "print(len(df))\n",
    "df = df[len(df)-2000000:]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e94020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to balance dataset by adding mirror of game but switching the colors\n",
    "def reverse_fen(fen):\n",
    "    board, turn, *rest = fen.split(\" \")\n",
    "    # 1. Swap piece colors\n",
    "    swapped = \"\".join(\n",
    "        c.lower() if c.isupper() else c.upper() if c.islower() else c\n",
    "        for c in board\n",
    "    )\n",
    "    # 2. Reverse ranks\n",
    "    ranks = swapped.split(\"/\")\n",
    "    reversed_board = \"/\".join(ranks[::-1])\n",
    "    # 3. Flip turn\n",
    "    new_turn = \"w\" if turn == \"b\" else \"b\"\n",
    "    # 4. Rebuild FEN\n",
    "    new_fen = \" \".join([reversed_board, new_turn] + rest)\n",
    "    return new_fen\n",
    "\n",
    "testFen = \"4k3/3pppp1/8/8/8/8/8/3QK3 w - - 0 1\"\n",
    "print(f'Reversing fen \"{testFen}\" to \"{reverse_fen(testFen)}\"')\n",
    "\n",
    "#Augment dataframe\n",
    "def augmentDf(df):\n",
    "    print(\"Original size:\", len(df))\n",
    "    augmented_rows = []\n",
    "    for _, row in tqdm(df.iterrows(),total=len(df),desc=\"Equalizing dataframe\",colour=\"green\",ncols=100):\n",
    "        newFen = reverse_fen(row[\"fen\"])\n",
    "        augmented_rows.append({\n",
    "            \"fen\" : newFen,\n",
    "            \"score_cp\" : row[\"score_cp\"],\n",
    "            \"score2_cp\" : row[\"score2_cp\"],\n",
    "        })\n",
    "    df_aug = pd.DataFrame(augmented_rows)\n",
    "    print(\"Augmented size:\", len(df_aug)+len(df))\n",
    "    return pd.concat([df, df_aug], ignore_index=True)\n",
    "\n",
    "df = augmentDf(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search df for black positions with high centipawn evaluations (for testing)\n",
    "def searchDf(df):\n",
    "    blackRows = []\n",
    "    for _, row in tqdm(df.iterrows(),total=len(df),desc=\"Searching dataframe\",colour=\"green\",ncols=100):\n",
    "        if row[\"fen\"].split()[1] == \"b\" and abs(row[\"score_cp\"]) >= 400:\n",
    "\n",
    "            blackRows.append({\n",
    "                \"fen\" : row[\"fen\"],\n",
    "                \"score_cp\" : row[\"score_cp\"],\n",
    "                \"score2_cp\" : row[\"score2_cp\"],\n",
    "            })\n",
    "    print(len(blackRows))\n",
    "    print(*blackRows,sep=\"\\n\")\n",
    "\n",
    "searchDf(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594c1d2",
   "metadata": {},
   "source": [
    "## 2) FEN encoder\n",
    "We encode each board into a feature vector: 64 squares × 12 piece planes (P,N,B,R,Q,K for white/black), plus side-to-move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e9a3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature length of vector: 782\n",
      "Feature length of image (8, 8, 12) and (13,)\n",
      "Feature length of flat (769,)\n",
      "Feature length of small flat (65,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIECE_TO_PLANE = {\n",
    "    'P':0,'N':1,'B':2,'R':3,'Q':4,'K':5,\n",
    "    'p':6,'n':7,'b':8,'r':9,'q':10,'k':11\n",
    "}\n",
    "\n",
    "def fen_to_flat(fen: str, debug=False):\n",
    "    parts = fen.strip().split()\n",
    "    board, side, castling, ep = parts[0], parts[1], parts[2], parts[3]\n",
    "    img = np.zeros((8,8,12), dtype=np.float16)\n",
    "    ranks = board.split('/')\n",
    "    for r, rank in enumerate(ranks):\n",
    "        file_idx = 0\n",
    "        for ch in rank:\n",
    "            if ch.isdigit():\n",
    "                file_idx += int(ch)\n",
    "            else:\n",
    "                img[r, file_idx, PIECE_TO_PLANE[ch]] = 1.0\n",
    "                file_idx += 1\n",
    "\n",
    "    if (debug):\n",
    "        print(\"8 x 8 x 12, without extras\")\n",
    "        print(*img)\n",
    "\n",
    "    features = []\n",
    "    features.extend(img.reshape(-1).tolist())\n",
    "\n",
    "    features.append(1.0 if side == 'w' else 0.0)\n",
    "\n",
    "    # return img.flatten()\n",
    "    return np.array(features, dtype=np.float16)\n",
    "\n",
    "# Quick sanity check\n",
    "x = fen_to_flat(df.iloc[0][\"fen\"])\n",
    "print(f\"Feature length of flat {x.shape}\")\n",
    "\n",
    "del x\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f3f11",
   "metadata": {},
   "source": [
    "## 3) Build feature matrix X and target y\n",
    "- `y_score` = first centipawn score (`score_cp`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8329066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = df['score_cp'].values.astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6a0405",
   "metadata": {},
   "source": [
    "### Prepare data for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e13cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formating NN training and validation data: 100%|\u001b[32m██████████\u001b[0m| 2000000/2000000 [03:24<00:00, 9770.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating np array to store data\n",
      "Splitting into training and test data\n",
      "Switching to float16 to reduce memory usage\n"
     ]
    }
   ],
   "source": [
    "board_imgs = []\n",
    "for fen,static_score in tqdm(zip(df[\"fen\"],df[\"score2_cp\"]),total=len(df),desc=\"Formating NN training and validation data\",colour=\"green\"):\n",
    "    img = fen_to_flat(fen)\n",
    "    img = np.append(img, np.float16(static_score))\n",
    "    board_imgs.append(img)\n",
    "\n",
    "print(\"Creating np array to store data\")\n",
    "board_imgs = np.array(board_imgs)\n",
    "\n",
    "print(\"Splitting into training and test data\")\n",
    "imgs_train, imgs_test, y_score_train, y_score_test = train_test_split(\n",
    "    board_imgs, y_score, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Switching to float16 to reduce memory usage\")\n",
    "imgs_train = imgs_train.astype(\"float16\")\n",
    "imgs_test = imgs_test.astype(\"float16\")\n",
    "y_score_train = y_score_train.reshape(-1, 1).astype(\"float16\")\n",
    "y_score_test  = y_score_test.reshape(-1, 1).astype(\"float16\")\n",
    "\n",
    "del board_imgs, y_score, PIECE_TO_PLANE, img\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e40a28b",
   "metadata": {},
   "source": [
    "## 4) NN for score prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8181cfd",
   "metadata": {},
   "source": [
    "Alternative loss functions for the NN, but testing shows that mse is the best loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65945e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse_by_true(eps=0.1, power=1.0):\n",
    "    \"\"\"\n",
    "    Weighted MSE where weight = 1 / (|y_true| + eps)**power, then normalized to mean 1.\n",
    "    - eps: avoids division by zero and controls how strong the upweighting for small y is.\n",
    "    - power: 1.0 => inverse absolute, 2.0 => inverse-square (stronger).\n",
    "    \"\"\"\n",
    "    def loss(y_true, y_pred):\n",
    "        # ensure floats\n",
    "        y_true_f = tf.cast(y_true, tf.float32)\n",
    "        y_pred_f = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "        # compute base MSE per sample (reduce over last axis if vector outputs)\n",
    "        sq_err = tf.reduce_mean(tf.square(y_pred_f - y_true_f), axis=-1)\n",
    "\n",
    "        # compute weights\n",
    "        w = 1.0 / (tf.abs(y_true_f) + eps)**power\n",
    "        # if y has shape (batch,1) reduce to (batch,)\n",
    "        w = tf.reshape(w, tf.shape(sq_err))\n",
    "\n",
    "        # normalize weights to mean 1 in the batch to keep gradient scale stable\n",
    "        w = w / (tf.reduce_mean(w) + 1e-12)\n",
    "\n",
    "        return tf.reduce_mean(w * sq_err)\n",
    "    return loss\n",
    "\n",
    "def relative_mse(eps=0.1):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true_f = tf.cast(y_true, tf.float32)\n",
    "        y_pred_f = tf.cast(y_pred, tf.float32)\n",
    "        denom = tf.abs(y_true_f) + eps\n",
    "        rel = (y_pred_f - y_true_f) / denom\n",
    "        return tf.reduce_mean(tf.square(rel))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb90b2e",
   "metadata": {},
   "source": [
    "The NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de7b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Would be incredible to be able to do a grid search on first layer size and next layer size and amount\n",
    "def build_chess_cnn():\n",
    "    board_input = Input(shape=(770,), dtype='float16', name=\"board\")\n",
    "    hidden = layers.Dense(32, activation=\"relu\",kernel_regularizer=l2(0.001))(board_input)\n",
    "    for i in range(7):\n",
    "        hidden = layers.Dense(16, activation=\"relu\",kernel_regularizer=l2(0.001))(hidden)\n",
    "    # hidden = layers.Dropout(0.20)(hidden)\n",
    "    value_out = layers.Dense(1, name=\"value\")(hidden)\n",
    "\n",
    "\n",
    "    # model = models.Model(inputs=[board_input, extra_input], outputs=[value_out])\n",
    "    model = models.Model(inputs=[board_input], outputs=[value_out])\n",
    "    model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\"value\": \"mse\"},\n",
    "    metrics={\"value\": [\"mae\"]}\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "#A NN just ot see if it works\n",
    "model = build_chess_cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b79c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arreter en cas d'overfitting ou de stagnation\n",
    "early_stop = EarlyStopping(monitor = \"val_loss\", patience = 5, restore_best_weights=True)\n",
    "\n",
    "#Permettre qu'il continue meme si plus lentement\n",
    "reduce_lr = ReduceLROnPlateau(monitor = \"val_loss\", mode = \"min\", factor = 0.5, patience = 3)\n",
    "\n",
    "#Train CNN model\n",
    "history = model.fit(\n",
    "    imgs_train,\n",
    "    y_score_train,\n",
    "    validation_data=[imgs_test,y_score_test],\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks = [early_stop, reduce_lr],\n",
    "    batch_size = 2048,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c923b70",
   "metadata": {},
   "source": [
    "## 5) Data I can visualize as a human to understand the ai's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa8c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "#Skip first outrageously large error\n",
    "plt.plot(history.history['loss'][1:], label=\"Train loss\")\n",
    "plt.plot(history.history['val_loss'][1:], label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb7a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test CNN model\n",
    "test_results = model.evaluate(\n",
    "    # {\"board\": imgs_test, \"extra\": extras_test},\n",
    "    imgs_test,\n",
    "    y_score_test,\n",
    "    batch_size=1024,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#Best result\n",
    "# MSE                 MAE\n",
    "# [754.0731201171875, 21.048927307128906]\n",
    "print(\"Test results:\", test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9a411",
   "metadata": {},
   "source": [
    "# Model prediction distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(imgs_test, batch_size=1024)\n",
    "\n",
    "errors = y_pred.flatten() - y_score_test.flatten()  # assuming 1D outputs\n",
    "\n",
    "# Plot distribution of errors\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(errors, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Prediction Errors')\n",
    "plt.xlabel('Error (Prediction - True)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Optional: print summary statistics\n",
    "print(\"Mean Absolute Error (MAE):\", np.mean(np.abs(errors)))\n",
    "print(\"Mean Squared Error (MSE):\", np.mean(errors**2))\n",
    "print(\"Max error:\", np.max(np.abs(errors)))\n",
    "\n",
    "large_limit = 30\n",
    "large_error_indices = np.where(np.abs(errors) > large_limit)[0]\n",
    "print(f\"There are {len(large_error_indices)} positions with >{large_limit}cp erros\")\n",
    "\n",
    "print(imgs_test[large_error_indices[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e5c83",
   "metadata": {},
   "source": [
    "# Model prediction heatmap by true-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c281af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_score_test.flatten()\n",
    "y_pred = model.predict(imgs_test, batch_size=1024, verbose=0).flatten()\n",
    "\n",
    "errors = y_pred - y_true\n",
    "\n",
    "true_bins = np.arange(-200, 200, 10)   # bins for true score (Y axis)\n",
    "error_bins = np.arange(-130, 130, 10)  # bins for error (X axis)\n",
    "\n",
    "# 2D histogram: H[true_bin, error_bin] = count\n",
    "H, xedges, yedges = np.histogram2d(y_true, errors,bins=[true_bins, error_bins])\n",
    "\n",
    "# Normalize each column (true-score bin) so it sums to 1\n",
    "col_sums = H.sum(axis=1, keepdims=True)\n",
    "H_norm = np.divide(H, col_sums, out=np.zeros_like(H), where=col_sums!=0)\n",
    "\n",
    "# Plot normalized heatmap\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.imshow(\n",
    "    H_norm.T,           # transpose: X=true value, Y=error\n",
    "    origin=\"lower\",\n",
    "    aspect=\"auto\",\n",
    "    extent=[true_bins[0], true_bins[-1], error_bins[0], error_bins[-1]],\n",
    "    cmap=\"turbo\",\n",
    "    vmin=0, vmax=np.max(H_norm)\n",
    ")\n",
    "plt.colorbar(label=\"Proportion within true-value bin\")\n",
    "plt.xlabel(\"True score\")\n",
    "plt.ylabel(\"Prediction error (pred − true)\")\n",
    "plt.title(\"Normalized error distribution by true-score range\")\n",
    "plt.axhline(0, color=\"k\", lw=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08701027",
   "metadata": {},
   "source": [
    "# True-score heatmap distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e07085",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_score_test.flatten()\n",
    "\n",
    "limit = 100\n",
    "bins = np.arange(-limit-1, limit+1, 1)  # bin width = 1\n",
    "hist, _ = np.histogram(y_true, bins=bins)\n",
    "\n",
    "# Normalize to get percentage per bin\n",
    "hist_percent = hist / hist.sum()\n",
    "\n",
    "# Create a 2D array for heatmap (1 row, n columns)\n",
    "heatmap = hist_percent[np.newaxis, :]  # shape (1, n_bins)\n",
    "\n",
    "plt.figure(figsize=(12, 2))  # wide and short\n",
    "plt.imshow(\n",
    "    heatmap,\n",
    "    aspect='auto',\n",
    "    cmap='turbo',\n",
    "    extent=[bins[0], bins[-1], 0, 1]\n",
    ")\n",
    "plt.colorbar(label='Percentage of true scores')\n",
    "plt.yticks([])  # hide Y axis\n",
    "plt.xlabel('True score value')\n",
    "plt.title('Distribution of True Scores as Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef96e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_eval(fen,static_eval):\n",
    "    x_input = fen_to_flat(fen,debug=False)\n",
    "    x_input = np.append(x_input, np.float32(static_eval))\n",
    "    print(*x_input,sep=\",\")\n",
    "    x_input = x_input.reshape(1, -1)\n",
    "\n",
    "    print(x_input.shape)\n",
    "    prediction = model.predict(x_input)\n",
    "    print(f\"Predicted evaluation (centipawns) for '{fen}' : {prediction[0][0]:.3f}\")\n",
    "\n",
    "predict_eval(\"r2qk4/8/8/8/8/8/PPPPPPPP/RNBQKBNR w KQq - 0 1\",2.390)\n",
    "predict_eval(\"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\",0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af256dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_limit = 100\n",
    "for i in tqdm(range(len(df)),desc=f\"Looking for errors >= {error_limit}\",total=len(df),colour=\"green\"):\n",
    "    x_input = fen_to_flat(df[\"fen\"][i])\n",
    "    x_input = np.append(x_input, np.float32(df[\"score2_cp\"][i]))\n",
    "    x_input = x_input.reshape(1, -1)\n",
    "\n",
    "    prediction = model.predict(x_input,verbose=0)\n",
    "    error = int(df['score_cp'][i])-(prediction[0][0])\n",
    "    if (abs(error) >= error_limit):\n",
    "        print(df.loc[[i]])\n",
    "        print(f\"Predicted evaluation (centipawns) for '{df['fen'][i]}' : {prediction[0][0]:.3f} accurate is {df['score_cp'][i]}, error is {error:.3f}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6440d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"best_on_doubled.keras\")\n",
    "model.export(\"best_tf_nn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e478406",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"best_on_doubled.keras\")  \n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
